{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "#\n",
    "# StockPriceCorrelator\n",
    "#\n",
    "# By James King\n",
    "#\n",
    "# Shows stock price reaction to descrete events\n",
    "#\n",
    "###############################################################################################\n",
    "%matplotlib inline\n",
    "##############################################################################################\n",
    "# Import libraries\n",
    "##############################################################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import pylab as plt\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta as dt_delta\n",
    "from pandas.io.json import json_normalize\n",
    "import requests\n",
    "import editdistance\n",
    "import pickle\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "#  Helper function definitions\n",
    "##############################################################################################\n",
    "def tickerLookupNasdaq():\n",
    "    '''Returns a pandas dataframe with all tickers & companies on the NYSE,\n",
    "    AMEX, and NASDAQ exchanges according to the NASDAQ website.'''\n",
    "    ## Download current company lists\n",
    "    exchanges = {'NYSE':'http://www.nasdaq.com/screening/companies-by-name.aspx?letter=0&exchange=nyse&render=download',\n",
    "    'AMEX':'http://www.nasdaq.com/screening/companies-by-name.aspx?letter=0&exchange=amex&render=download',\n",
    "    'NASDAQ':'http://www.nasdaq.com/screening/companies-by-name.aspx?letter=0&exchange=nasdaq&render=download'}\n",
    "\n",
    "    companies=[]\n",
    "    for ex in exchanges.keys():\n",
    "        saveFileName = ex + '_company_list.csv'\n",
    "        companies.append(saveFileName)\n",
    "        url = exchanges[ex]\n",
    "        r = requests.get(url)\n",
    "\n",
    "        with open(saveFileName,'w') as output:\n",
    "            output.write(r.content)\n",
    "\n",
    "    codf = pd.DataFrame()\n",
    "    for co in companies:\n",
    "        codf = pd.concat([codf, pd.read_csv(co)])\n",
    "\n",
    "    return codf\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "def tickerLookupOats():\n",
    "    '''Returns all tickers & companies from the OATS webpage in a pandas dataframe'''\n",
    "    \n",
    "    url = 'http://oatsreportable.finra.org/OATSReportableSecurities-SOD.txt'\n",
    "    # returns a pipe-delimited text file\n",
    "    r = pd.DataFrame.from_csv(url, sep='|', index_col=False)\n",
    "    \n",
    "    return r\n",
    "\n",
    "##############################################################################################\n",
    "def tickerLookupYahoo(searchTermString, \n",
    "                      exchange_list = ['NYSE','AMEX','NASDAQ'], \n",
    "                      return_closest = True, \n",
    "                      verbose = False):\n",
    "    \n",
    "    '''Given a string of search words (separated by spaces), returns\n",
    "        a pandas data frame with the responses from Yahoo.  If exchange is set,\n",
    "        filter results to include only the exchanges listed.  Set to None for any\n",
    "        exchange.'''\n",
    "\n",
    "    try:\n",
    "\n",
    "        searchTermString = searchTermString.replace(' ','+')\n",
    "        url = 'http://d.yimg.com/aq/autoc?query=' + searchTermString + '&region=US&lang=en-US'\n",
    "        js = pd.read_json(url)\n",
    "        r = json_normalize(js.ResultSet.Result)\n",
    "\n",
    "        if exchange_list is not None:\n",
    "            r = r[r['exchDisp'].isin(exchange_list)]\n",
    "\n",
    "        if return_closest:\n",
    "            distances = [editdistance.eval(searchTermString.replace('+',' '), word) for word in r.name]\n",
    "            #print distances\n",
    "            return r[distances == np.min(distances)]\n",
    "\n",
    "        else:\n",
    "            return r\n",
    "    \n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print 'Search term(s) not found: ', e\n",
    "        return None\n",
    "    \n",
    "##############################################################################################\n",
    "def fetchStockPrices(query_symbol='T', incident_date='2010-06-16',pm_days = 14):\n",
    "    incident_date = dt.strptime(incident_date,'%Y-%m-%d')\n",
    "    pm_delta = dt_delta(days=14)\n",
    "    query_start_date = str((incident_date - pm_delta).date())\n",
    "    query_end_date = str((incident_date + pm_delta).date())\n",
    "\n",
    "    query_url = '''https://query.yahooapis.com/v1/public/''' + \\\n",
    "    '''yql?q=select%20*%20from%20yahoo.finance.historicaldata%20where%20'''+ \\\n",
    "    '''symbol%20%3D%20%22'''    + query_symbol + '''%22%20and%20'''+ \\\n",
    "    '''startDate%20%3D%20%22''' + query_start_date + '''%22%20and%20'''+ \\\n",
    "    '''endDate%20%3D%20%22'''   + query_end_date +'''%22&format=json&'''+ \\\n",
    "    '''diagnostics=false&env=store%3A%2F%2Fdatatables.org%2Falltableswithkeys'''\n",
    "\n",
    "    try:\n",
    "        stock_prices_json = pd.read_json(query_url)\n",
    "        stock_prices_df = json_normalize(stock_prices_json.iloc[3].query['quote'])\n",
    "                     \n",
    "        return stock_prices_df\n",
    "    except Exception as e:\n",
    "        print query_url, ' returned no data'\n",
    "        return None\n",
    "    \n",
    "##############################################################################################\n",
    "def fetchIndexPrices(incident_date='2010-06-16',pm_days = 14):\n",
    "    nasdaq_composite = '^IXIC'\n",
    "    sp_composite = '^GSPC'\n",
    "    dj_composite = '^DJI'\n",
    "    \n",
    "    nasdaq_df = fetchStockPrices(query_symbol = nasdaq_composite, \n",
    "                                 incident_date = incident_date, pm_days = pm_days)\n",
    "    \n",
    "    sp_df = fetchStockPrices(query_symbol = sp_composite, \n",
    "                                 incident_date = incident_date, pm_days = pm_days)\n",
    "    \n",
    "    dj_df = fetchStockPrices(query_symbol = dj_composite, \n",
    "                                 incident_date = incident_date, pm_days = pm_days)\n",
    "    \n",
    "    return nasdaq_df, sp_df, dj_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File breaches.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-538c82574cc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m##############################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mraw_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'breaches.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib64/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    527\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib64/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib64/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib64/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib64/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1117\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1119\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3246)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6111)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File breaches.csv does not exist"
     ]
    }
   ],
   "source": [
    "##############################################################################################\n",
    "# Load data about breaches\n",
    "##############################################################################################\n",
    "\n",
    "raw_data = pd.read_csv('breaches.csv', header=0)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Name'] = raw_data.Name\n",
    "df['Date_String'] = raw_data[[1]]\n",
    "df['Place'] = raw_data.Location\n",
    "\n",
    "## Get rid of rows without dates\n",
    "df = df.dropna(axis=0, subset=['Date_String'])\n",
    "\n",
    "#Convert dates to computer-friendly format\n",
    "df['Date'] = [dt.strptime(ds, '%B %d, %Y') for ds in df.Date_String]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-66f658709e5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mhits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mcompany_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mbork\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mtickerLookupYahoo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcompany_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_closest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "##############################################################################################\n",
    "# Check each breached organization name against the Yahoo Finance ticker symbol lookup API\n",
    "#  and store results.   Many organizations have several possible matches which will need to be \n",
    "#  worked through by hand.\n",
    "##############################################################################################\n",
    "\n",
    "try:\n",
    "    # Attempt to load the data from disk, first\n",
    "    hits = pickle.load(open('yahoo_hits.pickle'))\n",
    "    \n",
    "except:    \n",
    "    hits = []\n",
    "    print \n",
    "    for company_index in range(len(df.Name)):\n",
    "        try:\n",
    "            bork =  tickerLookupYahoo(df.iloc[company_index].Name,return_closest=False)\n",
    "            if bork is not None:\n",
    "                print bork.symbol[1]\n",
    "                hits.append(bork)\n",
    "            else:\n",
    "                hits.append(None)\n",
    "\n",
    "        except Exception as e:\n",
    "            hits.append(None)\n",
    "\n",
    "        print '\\r'+str(len(hits))+' of '+str(len(df.Name)),\n",
    "\n",
    "        if len(hits) > 5000:\n",
    "            break\n",
    "    pickle.dump(hits,open('yahoo_hits.pickle','w'))\n",
    "        \n",
    "df['yahoo_hits']=hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "# Add tickers to companies which have them in df and discard the rest.  \n",
    "##############################################################################################\n",
    "\n",
    "# Load hand-edited ticker file\n",
    "tickers = pd.DataFrame.from_csv('corrFileEditedUnique.csv', sep='|', index_col=False,header=None)\n",
    "tickers.columns = ['breach_company_name','yahoo_symbol','yahoo_company_name','exchange']\n",
    "\n",
    "# Strip extra spaces off the names of companies\n",
    "df.Name = df.Name.str.strip()\n",
    "tickers.breach_company_name = tickers.breach_company_name.str.strip()\n",
    "tickers.yahoo_company_name = tickers.yahoo_company_name.str.strip()\n",
    "tickers.yahoo_symbol = tickers.yahoo_symbol.str.strip()\n",
    "\n",
    "# Merge yahoo ticker data with breach data\n",
    "merged = pd.merge(df, tickers, how='inner', on=None, left_on='Name', right_on='breach_company_name',\n",
    "      left_index=False, right_index=False, sort=True)\n",
    "\n",
    "# Get rid of uninteresting columns\n",
    "merged.drop('breach_company_name', axis=1, inplace=True)\n",
    "merged.drop('yahoo_hits', axis=1, inplace=True)\n",
    "\n",
    "# Save for posteritypriceList = []\n",
    "\n",
    "\n",
    "for entry in merged.index:\n",
    "    thisDate = str(merged.iloc[entry].Date).split()[0]\n",
    "    thisSym = str(merged.iloc[entry].yahoo_symbol)\n",
    "    priceList.append(fetchStockPrices(query_symbol = thisSym, incident_date = thisDate))\n",
    "pickle.dump(merged,open('public_companies.csv','w'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4558585770a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m##############################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mfull_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mfull_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prices'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpriceList\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mkeeps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfull_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mxx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'merged' is not defined"
     ]
    }
   ],
   "source": [
    "##############################################################################################\n",
    "# Add results to data frame & get rid of incidents w/o data (these were probably\n",
    "#  not publicly traded at the time of the incident announcement)\n",
    "##############################################################################################\n",
    "\n",
    "full_df = merged\n",
    "full_df['prices']=priceList\n",
    "keeps = [full_df.prices[xx] is not None for xx in range(len(full_df))]\n",
    "full_df = full_df[keeps]\n",
    "full_df.iloc[40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "    \n",
    "    \n",
    "def plotBreachChart(full_df, current_incident=0, include_index = 'sp'):\n",
    "    \n",
    "    f = plt.figure()\n",
    "    ax = plt.gca()\n",
    "    this_prices_df = full_df.prices[current_incident]\n",
    "    this_prices_df = this_prices_df.iloc[::-1] # data are returned with newest first--fix\n",
    "    plt.plot(this_prices_df.Close,'.-')\n",
    "    plt.hold('on')\n",
    "    #plt.plot(this_prices_df.Open,'r.-')\n",
    "    plt.ylabel('Share Price at Close ($)')\n",
    "    plt.xticks(range(len(this_prices_df)),np.array(this_prices_df.Date))\n",
    "    f.autofmt_xdate(rotation=90)\n",
    "\n",
    "        \n",
    "\n",
    "    # Find the appropriate place to draw a reference line\n",
    "    before_incident_bool=list(full_df.Date[current_incident].strftime('%Y-%m-%d')<=this_prices_df.Date)  # '>=' because incidents don't always happen on a day with market data \n",
    "    incident_index = before_incident_bool.index(True)\n",
    "    #print 'Date of Incident: ', full_df.Date[current_incident]\n",
    "    this_prices_df.Date[incident_index]\n",
    "\n",
    "    ax.axvline(incident_index, color='m', linestyle='--')\n",
    "    title_text='Stock Price Before and \\nAfter Breach Announcement'\n",
    "    title_text += '\\nCompany: '+ full_df.yahoo_company_name[current_incident] \n",
    "    title_text += ' (' + full_df.yahoo_symbol[current_incident] + ')'\n",
    "    plt.title(title_text)\n",
    "    plt.xlabel('Date')\n",
    "    #plt.ylabel('Price ($)')\n",
    "    #plt.legend(['Opening Price','Closing Price'])\n",
    "    \n",
    "    # Draw the index fund on the right vertical\n",
    "    if include_index == 'sp':\n",
    "        ax2 = ax.twinx()\n",
    "        nasdaq, sp, dj = fetchIndexPrices(\n",
    "            incident_date=full_df.Date[current_incident].strftime('%Y-%m-%d'))\n",
    "        ax2.plot(sp.Close,'.-',color='0.75')\n",
    "        plt.ylabel('S&P 500 Composite at Close ($)')\n",
    "\n",
    "#f = plt.gcf()\n",
    "#plt.figure(num=None, figsize=(10, 15), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "counter = 0 #use this instead of current_incident as incident #s aren't necessarily sequential\n",
    "for current_incident in full_df.index:\n",
    "    #plt.subplot(70,2,counter)\n",
    "    plotBreachChart(full_df, current_incident)\n",
    "    #f = plt.gcf()\n",
    "    #f.autofmt_xdate(rotation=90)\n",
    "    #plt.subplots_adjust(left=None, bottom=5, right=None, top=15, wspace=1, hspace=1)\n",
    "    counter += 1\n",
    "    if counter > 2:\n",
    "        break\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "ups = 0\n",
    "downs = 0\n",
    "nones = 0\n",
    "#def breach_t_test():\n",
    "for current_incident in full_df.index:\n",
    "    #current_incident=33\n",
    "    this_prices_df = full_df.prices[current_incident]\n",
    "    this_prices_df = this_prices_df.iloc[::-1] # data are returned with newest first--fix\n",
    "    this_prices_df.Close.apply(str)\n",
    "    before = np.array(this_prices_df.Close.loc[:10],dtype=float)\n",
    "    after = np.array(this_prices_df.Close.loc[10:],dtype=float)\n",
    "\n",
    "    s,p = ttest_ind(before, after)\n",
    "    \n",
    "    if (p < 0.05) and (np.mean(before)>np.mean(after)):\n",
    "        #print p, np.mean(before), np.mean(after), 'Significant Drop'\n",
    "        downs += 1\n",
    "    elif (p < 0.05) and (np.mean(before)<np.mean(after)):\n",
    "          #print p, np.mean(before), np.mean(after), 'Significant Rise'\n",
    "        ups += 1\n",
    "    else:\n",
    "        #print p, np.mean(before), np.mean(after), 'No effect'\n",
    "        nones += 1\n",
    "\n",
    "print 'Sig Rise: ', float(ups)/len(full_df.index)\n",
    "print 'Sig Drop: ', float(downs)/len(full_df.index)\n",
    "print 'No Change: ',float(nones)/len(full_df.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
